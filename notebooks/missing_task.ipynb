{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前言\n",
    "\n",
    "旨在在搭建模态缺失任务时的思考和测试代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def add_project_root_to_sys_path():\n",
    "    \"\"\"动态添加项目根目录到 sys.path\"\"\"\n",
    "    project_root = Path.cwd().resolve().parent\n",
    "    if str(project_root) not in sys.path:\n",
    "        sys.path.append(str(project_root))\n",
    "\n",
    "add_project_root_to_sys_path()\n",
    "# print('\\n'.join(sys.path))\n",
    "\n",
    "from common.utils import load_config\n",
    "from data.Dataset import FeatureDataset\n",
    "from data.LoadFeatures import DataFeatures\n",
    "from models.Models import  MFAFESM\n",
    "from common.process_graph import initialize_graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 寻找中间模态数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['eeg', 'eye', 'pps', 'arousal_label', 'valence_label', 'subject_list', 'ch_info', 'info'])\n",
      "EEG: 1-70filer, 50Hz notch, 256Hz resample;\n",
      "Subject : 1-30 subject, no 3,9,12,15,16,25 subject; 24 person, 20 trial, 32 EEG channel, 7 pps channels;\n",
      "Labels :    Arousal: 0:[\"Sadness\", \"Disgust\", \"Neutral\"]、1:[\"Joy, Happiness\", \"Amusement\"] 2:[\"Surprise\", \"Fear\", \"Anger\", \"Anxiety\"]\n",
      "    Valence: 0:[\"Fear\", \"Anger\", \"Disgust\", \"Sadness\", \"Anxiety\"] 1:[\"Surprise\", \"Neutral\"] 2:[\"Joy, Happiness\", \"Amusement\"]\n",
      "Eye Track data : DistanceLeft，PupilLeft，ValidityLeft，Distance Right，Pupil Right，Validity Right，Fixation Index，Gaze Point X，Gaze Point Y，Fixation Duration\n",
      "     PPS data : ECG, GSR，Resp，Temp，Status\n",
      "开始加载眼动特征...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Subjects: 100%|██████████| 24/24 [00:00<00:00, 3799.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "眼动特征加载完成。\n",
      "开始加载PPS特征...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Subjects: 100%|██████████| 24/24 [00:00<00:00, 1657.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPS特征加载完成。\n",
      "{'type': 'iterative_fusion', 'feature_extract': {'input_dim': 585, 'hidden_dim': 160, 'tok': 0.5}, 'feature_align': {'input_size': [960, 38, 230], 'embed_dim': 160, 'seq_len': 10}, 'fusion': {'embed_dim': 160, 'num_heads': 8, 'd_model': 960}, 'attention_encoder': {'num_layers': 6, 'd_model': 960, 'num_heads': 8, 'd_ff': 2048, 'dropout': 0.1, 'embed_dim': 160}, 'classifier': {'nb_classes': 3, 'embed_dim': 1600}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config_path = Path.cwd().resolve().parent / 'config' / 'config.yaml'\n",
    "config = load_config(config_path)\n",
    "config['data'] = config['data']['HCI']\n",
    "data = DataFeatures(\n",
    "    data_path=config[\"data\"][\"data_path\"],\n",
    "    modalities=config[\"training\"][\"using_modalities\"],\n",
    "    subject_lists=config[\"data\"][\"subject_lists\"],\n",
    "    Norm=\"Z_score\",\n",
    "    label_type=config['data']['label_type'],\n",
    ")\n",
    "\n",
    "test_person = 0\n",
    "config[\"training\"][\"missing_task\"][\"checkpoint_dir\"] = os.path.join(\n",
    "    config[\"training\"][\"missing_task\"][\"checkpoint_dir\"],\n",
    "    f\"best_checkpoint_{test_person}.pth\",\n",
    ")\n",
    "\n",
    "# 修改model配置\n",
    "config['model'] = config['model']['MFAFESM']\n",
    "config[\"model\"][\"classifier\"][\"nb_classes\"] = config[\"num_classes\"]\n",
    "config[\"model\"][\"feature_extract\"][\"input_dim\"] = config[\"data\"][\"input_dim\"]\n",
    "\n",
    " # 根据模态修改输入维度\n",
    "using_modality = config[\"training\"][\"using_modalities\"]\n",
    "\n",
    "input_size = config[\"data\"][\"input_size\"]\n",
    "new_input_size = []\n",
    "if using_modality is not None:\n",
    "    for modality in using_modality:\n",
    "        if modality == \"eeg\":\n",
    "            new_input_size.append(input_size[0])\n",
    "        elif modality == \"eye\":\n",
    "            new_input_size.append(input_size[1])\n",
    "        elif modality == \"au\" or modality == \"pps\":\n",
    "            new_input_size.append(input_size[2])\n",
    "    config[\"training\"][\"using_modalities\"] = using_modality\n",
    "\n",
    "    config[\"data\"][\"input_size\"] = new_input_size\n",
    "    config[\"model\"][\"feature_align\"][\"input_size\"] = new_input_size\n",
    "\n",
    "d_model = config[\"model\"][\"fusion\"][\"d_model\"]\n",
    "# 根据模态修改模型维度（zhe'k\n",
    "swell = 1\n",
    "if config[\"model\"][\"type\"] == \"major_modality_fusion\":\n",
    "    if len(using_modality) > 1:\n",
    "        swell = 2\n",
    "elif config[\"model\"][\"type\"] == \"iterative_fusion\":\n",
    "    swell = 3\n",
    "elif config[\"model\"][\"type\"] == \"full_compose_fusion\":\n",
    "    swell = 6\n",
    "elif config[\"model\"][\"type\"] == \"add_fusion\":\n",
    "    swell = 1.5\n",
    "config[\"model\"][\"fusion\"][\"d_model\"] = d_model * int(swell * 2)\n",
    "config[\"model\"][\"attention_encoder\"][\"d_model\"] = d_model * int(swell * 2)\n",
    "print(config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = FeatureDataset(\n",
    "    data,\n",
    "    ex_nums = config['data']['ex_nums'],\n",
    "    mode = \"train\",\n",
    "    test_person = test_person,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data.Dataset.FeatureDataset at 0x7f4e522f3820>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找到小搓代表性数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = trainSet.labels\n",
    "# print(labels)\n",
    "labels = np.array(labels)\n",
    "# 获取每个类别的索引\n",
    "category_indices = {category: np.where(labels == category)[0] for category in np.unique(labels)}\n",
    "\n",
    "# 设定每个类别要选取的样本数\n",
    "samples_per_category = 64 // len(category_indices)  # 每个类别选取相同数量的样本\n",
    "\n",
    "# 随机选取每个类别的索引\n",
    "selected_indices = []\n",
    "for category, indices in category_indices.items():\n",
    "    np.random.seed(42)  # 确保每次运行结果一致\n",
    "    selected_indices.extend(np.random.choice(indices, samples_per_category, replace=False))\n",
    "\n",
    "# 输出选中的索引\n",
    "selected_indices = np.array(selected_indices)\n",
    "print(\"Selected Indices: \", selected_indices)\n",
    "print(labels[selected_indices])\n",
    "\n",
    "print(np.unique(labels[selected_indices], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {}\n",
    "for key, value in trainSet.features.items():\n",
    "    new_data[key] = value[selected_indices]\n",
    "\n",
    "for key, value in new_data.items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据小搓数据加载模型中间输出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MFAFESM(config['model'])\n",
    "model = model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(config[\"training\"][\"missing_task\"][\"checkpoint_dir\"])\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def process_input(inputs):\n",
    "    \"\"\"处理输入数据，确保其正确放到设备上，并且转换成torch.float32\"\"\"\n",
    "    return_inputs = {}\n",
    "    for key in using_modality:\n",
    "        if inputs.get(key, None) is not None:\n",
    "            if not isinstance(inputs[key], torch.Tensor):\n",
    "                inputs[key] = torch.tensor(inputs[key])\n",
    "            return_inputs[key] = inputs[key].to(device).to(torch.float32)\n",
    "        else:\n",
    "            return_inputs[key] = None\n",
    "    return return_inputs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据加载的模型，获取中间层的输出\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    adj, graph_indicator = initialize_graph(config['data'], data_len = 63, device = device)\n",
    "    eeg, eye, au = process_input(new_data)\n",
    "\n",
    "    result, fused_features, encoded_features = model(adj, graph_indicator, eeg, eye, au, pps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.shape)\n",
    "print(fused_features.shape)\n",
    "print(encoded_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型参数查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.Models import MFAFESM\n",
    "# model = MFAFESM(config['model'], config['training'], config['data'])\n",
    "import torch\n",
    "model = torch.load(config[\"training\"][\"missing_task\"][\"checkpoint_dir\"])\n",
    "print(model.keys()) # dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict'])\n",
    "\n",
    "# 这么来看的话还是需要初始化模型\n",
    "model_state_dict = model['model_state_dict']\n",
    "for name, param in model_state_dict.items():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拿到融合部分的attention块权重可视化成热图看看\n",
    "fn_weights = model_state_dict['fusion.fn.weight'] + model_state_dict['fusion.fn.bias']\n",
    "print(fn_weights.size())\n",
    "fn_weights = fn_weights.cpu().numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(fn_weights, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画一下直方图\n",
    "plt.hist(fn_weights.flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取浅层encoder和深层encoder的ffn层的权重\n",
    "shallow_ffn_weights = model_state_dict['attention_encoder.encoder_layer.0.ff.linear_2.weight'] \n",
    "deep_ffn_weights = model_state_dict['attention_encoder.encoder_layer.5.ff.linear_2.weight'] \n",
    "# 可视化热图\n",
    "\n",
    "plt.imshow(shallow_ffn_weights.cpu().numpy(), cmap='hot', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(deep_ffn_weights.cpu().numpy(), cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看下直方图\n",
    "plt.hist(shallow_ffn_weights.cpu().numpy().flatten(), bins=100)\n",
    "plt.hist(deep_ffn_weights.cpu().numpy().flatten(), bins=100, color='r')\n",
    "plt.hist(fn_weights.flatten(), bins=100)\n",
    "plt.legend(['shallow', 'deep', 'fusion'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 将两种直方图合并到一起，采用不同的颜色"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
